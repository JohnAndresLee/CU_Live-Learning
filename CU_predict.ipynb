{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N3c5U3DiM0J3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3c5U3DiM0J3",
        "outputId": "09ff1eac-9e2a-4038-e443-ff7dc3cea36e"
      },
      "outputs": [],
      "source": [
        "! pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "794c5b79-a6e3-44db-9ac4-135888652d3a",
      "metadata": {
        "id": "794c5b79-a6e3-44db-9ac4-135888652d3a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "from torchinfo import summary\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from multiprocessing import Pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "011c3e28-af79-448e-9e82-27d3b14eb232",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "011c3e28-af79-448e-9e82-27d3b14eb232",
        "outputId": "9cb3f9bf-7b75-4430-ca0e-3b9a7e302902"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea7f74d-1347-4cfa-905c-47982cefdb1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "aea7f74d-1347-4cfa-905c-47982cefdb1a",
        "outputId": "437a1c60-daf6-4a9a-c65d-587422961eca"
      },
      "outputs": [],
      "source": [
        "path = './data/CU0.csv'\n",
        "\n",
        "data = pd.read_csv(path)\n",
        "data.replace(-121, np.nan, inplace=True)\n",
        "print(set(data['TradingDay'].values))\n",
        "data = data[['TradingDay', 'LastPrice', 'PreSettlementPrice', 'PreClosePrice',\n",
        "             'PreOpenInterest', 'OpenPrice', 'HighestPrice', 'LowestPrice', 'OpenInterest',\n",
        "             'BidPrice1', 'BidVolume1', 'AskPrice1', 'AskVolume1',\n",
        "             'BidPrice2', 'BidVolume2', 'AskPrice2', 'AskVolume2',\n",
        "             'BidPrice3', 'BidVolume3', 'AskPrice3', 'AskVolume3',\n",
        "             'BidPrice4', 'BidVolume4', 'AskPrice4', 'AskVolume4',\n",
        "             'BidPrice5', 'BidVolume5', 'AskPrice5', 'AskVolume5',\n",
        "             'delta_Volume', 'delta_Turnover']]\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "050f9f01-4d7c-460d-907b-445e2d9c8376",
      "metadata": {
        "id": "050f9f01-4d7c-460d-907b-445e2d9c8376"
      },
      "outputs": [],
      "source": [
        "# feature_cols = ['BidPrice1', 'BidVolume1', 'AskPrice1', 'AskVolume1',\n",
        "#              'BidPrice2', 'BidVolume2', 'AskPrice2', 'AskVolume2',\n",
        "#              'BidPrice3', 'BidVolume3', 'AskPrice3', 'AskVolume3',\n",
        "#              'BidPrice4', 'BidVolume4', 'AskPrice4', 'AskVolume4',\n",
        "#              'BidPrice5', 'BidVolume5', 'AskPrice5', 'AskVolume5',\n",
        "#              'delta_Volume', 'delta_Turnover']\n",
        "\n",
        "feature_cols = ['BidPrice1', 'BidVolume1', 'AskPrice1', 'AskVolume1',\n",
        "             'BidPrice2', 'BidVolume2', 'AskPrice2', 'AskVolume2',\n",
        "             'BidPrice3', 'BidVolume3', 'AskPrice3', 'AskVolume3',\n",
        "             'BidPrice4', 'BidVolume4', 'AskPrice4', 'AskVolume4',\n",
        "             'BidPrice5', 'BidVolume5', 'AskPrice5', 'AskVolume5']\n",
        "\n",
        "price_cols = ['BidPrice1', 'AskPrice1', 'BidPrice2',\n",
        "              'AskPrice2', 'BidPrice3', 'AskPrice3',\n",
        "              'BidPrice4', 'AskPrice4', 'BidPrice5', 'AskPrice5']\n",
        "\n",
        "vol_cols = ['BidVolume1', 'AskVolume1', 'BidVolume2', 'AskVolume2',\n",
        "            'BidVolume3', 'AskVolume3', 'BidVolume4', 'AskVolume4',\n",
        "            'BidVolume5', 'AskVolume5']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "563ed3b1-c153-424a-8b3c-2b40f040205b",
      "metadata": {
        "id": "563ed3b1-c153-424a-8b3c-2b40f040205b"
      },
      "outputs": [],
      "source": [
        "def data_preprocess(raw_data, ret_window = 120):\n",
        "    raw_data['midprice'] = (raw_data['BidPrice1']+raw_data['AskPrice1'])/2\n",
        "    raw_data['fut_midprice'] = raw_data['midprice'].shift(-ret_window)\n",
        "    raw_data['label'] = 100*(raw_data['fut_midprice']-raw_data['midprice'])/raw_data['midprice']\n",
        "\n",
        "    raw_data['midvolume'] = (raw_data['BidVolume1']+raw_data['AskVolume1'])/2\n",
        "\n",
        "    # price_rolling_mean = raw_data['midprice'].rolling(window=10).mean()\n",
        "    # volume_rolling_mean = raw_data['midvolume'].rolling(window=10).mean()\n",
        "\n",
        "    # raw_data['rolling_midprice'] = price_rolling_mean\n",
        "    # raw_data['rolling_midvolume'] = volume_rolling_mean\n",
        "\n",
        "    raw_data.drop(raw_data.tail(ret_window).index, inplace=True)\n",
        "    raw_data.drop(raw_data.head(10).index, inplace=True)\n",
        "\n",
        "    label = raw_data[['label']].values\n",
        "\n",
        "    # raw_data[vol_cols] = raw_data[vol_cols].div(raw_data['rolling_midvolume'], axis=0)\n",
        "    # raw_data[price_cols] = raw_data[price_cols].div(raw_data['rolling_midprice'], axis=0)-1\n",
        "    # raw_data[price_cols] = 10000*raw_data[price_cols]\n",
        "    # raw_data[vol_cols] = np.log(raw_data[vol_cols])\n",
        "    raw_data = raw_data[feature_cols].values\n",
        "\n",
        "    return raw_data, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23d646f1-5bdf-4f51-94a4-e5ea39890700",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23d646f1-5bdf-4f51-94a4-e5ea39890700",
        "outputId": "d6470b96-2301-470d-9a3b-462b0d4c38ee"
      },
      "outputs": [],
      "source": [
        "dataset = data_preprocess(data)\n",
        "del data\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Omkl7NXQxyPs",
      "metadata": {
        "id": "Omkl7NXQxyPs"
      },
      "outputs": [],
      "source": [
        "plt.hist(dataset[1], bins=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "347b6df9-9347-4b01-af78-fae704aaa094",
      "metadata": {
        "id": "347b6df9-9347-4b01-af78-fae704aaa094"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, period=600, small_period=1):\n",
        "        self.data = data\n",
        "        self.period = period\n",
        "        self.processed_data_x = []\n",
        "        self.processed_data_y = []\n",
        "\n",
        "        for i in range(period, len(data[0]), small_period):\n",
        "            self.processed_data_x.append(data[0][i-period:i, :])\n",
        "            self.processed_data_y.append(data[1][i-1])\n",
        "\n",
        "        self.processed_data_x = np.stack(self.processed_data_x, axis=0)\n",
        "        self.processed_data_y = np.stack(self.processed_data_y, axis=0)\n",
        "\n",
        "    def __len__(self) :\n",
        "        return len(self.processed_data_y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.processed_data_x[idx, :,:], self.processed_data_y[idx, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "418b3c94-e8db-45a7-9c10-2d77f653edb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "418b3c94-e8db-45a7-9c10-2d77f653edb5",
        "outputId": "ae9bf207-434d-445b-8c67-31ba8e5f5665"
      },
      "outputs": [],
      "source": [
        "train_data = MyDataset((dataset[0][:int(0.8*len(dataset[0])), :], dataset[1][:int(0.8*len(dataset[0])), :]), 600, 20)\n",
        "val_data = MyDataset((dataset[0][int(0.8*len(dataset[0])): int(0.9*len(dataset[0])), :], dataset[1][int(0.8*len(dataset[0])): int(0.9*len(dataset[0])), :]), 600, 20)\n",
        "test_data = MyDataset((dataset[0][int(0.9*len(dataset[0])):, :], dataset[1][int(0.9*len(dataset[0])):, :]), 600, 20)\n",
        "print(len(train_data))\n",
        "print(len(val_data))\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "6c93e51b-802a-4542-a061-40f407126a7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c93e51b-802a-4542-a061-40f407126a7d",
        "outputId": "3f39d571-2846-4d9d-94f4-5621ef081306"
      },
      "outputs": [],
      "source": [
        "train_data = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_data = DataLoader (val_data, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_data = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "e43d8602-ab5b-4d95-b4db-f0aea0bd04ad",
      "metadata": {
        "id": "e43d8602-ab5b-4d95-b4db-f0aea0bd04ad"
      },
      "outputs": [],
      "source": [
        "class MyLSTM(nn.Module):\n",
        "    def __init__(self, y_len):\n",
        "        super().__init__()\n",
        "        self.y_len = y_len\n",
        "\n",
        "        # convolution blocks\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "#             nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(24,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(24,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
        "            nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(24,1)),\n",
        "            nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(24,1)),\n",
        "            nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,5)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(24,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(24,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "\n",
        "        # inception moduels\n",
        "        self.inp1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(18,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        self.inp2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(15,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        self.inp3 = nn.Sequential(\n",
        "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "\n",
        "        # lstm layers\n",
        "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.fc1 = nn.Linear(64, self.y_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # h0: (number of hidden layers, batch size, hidden size)\n",
        "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
        "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
        "\n",
        "        x = torch.unsqueeze(x, 1)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "\n",
        "        x_inp1 = self.inp1(x)\n",
        "        x_inp2 = self.inp2(x)\n",
        "        x_inp3 = self.inp3(x)\n",
        "\n",
        "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
        "\n",
        "#         x = torch.transpose(x, 1, 2)\n",
        "        x = x.permute(0, 2, 1, 3)\n",
        "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
        "\n",
        "        x, _ = self.lstm(x, (h0, c0))\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc1(x)\n",
        "        forecast_y = torch.softmax(x, dim=1)\n",
        "\n",
        "        return forecast_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81121d6a-a9b9-4992-912f-34b121ac2984",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81121d6a-a9b9-4992-912f-34b121ac2984",
        "outputId": "627655c3-8d55-4133-b83c-12318eb146f6"
      },
      "outputs": [],
      "source": [
        "model = MyLSTM(1)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a66d7643-196c-4851-8632-4287c5c5eb11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a66d7643-196c-4851-8632-4287c5c5eb11",
        "outputId": "0db74010-3019-4bcb-8ceb-11eb7cf3f9c7"
      },
      "outputs": [],
      "source": [
        "def xavier_init(m):\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.LSTM):\n",
        "        for name, param in m.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "\n",
        "model.apply(xavier_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "885c0953-1841-4883-9d19-076180f3cb4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "885c0953-1841-4883-9d19-076180f3cb4e",
        "outputId": "88a372ca-c932-491c-fd4b-2314565c53eb"
      },
      "outputs": [],
      "source": [
        "summary(model, (16, 600, 20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "84bf42c6-eac4-48ff-824c-e36fa3ee0fc7",
      "metadata": {
        "id": "84bf42c6-eac4-48ff-824c-e36fa3ee0fc7"
      },
      "outputs": [],
      "source": [
        "class HuberLoss(nn.Module):\n",
        "    def __init__(self, delta=1.0):\n",
        "        super(HuberLoss, self).__init__()\n",
        "        self.delta = delta\n",
        "\n",
        "    def forward(self, prediction, target):\n",
        "        error = prediction - target\n",
        "        abs_error = torch.abs(error)\n",
        "        quadratic_part = torch.clamp(abs_error, max=self.delta)\n",
        "        linear_part = abs_error - quadratic_part\n",
        "        loss = 0.5 * quadratic_part ** 2 + self.delta * linear_part\n",
        "        return torch.mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "cb9edc71-75ea-4631-ba02-ede79e828625",
      "metadata": {
        "id": "cb9edc71-75ea-4631-ba02-ede79e828625"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b515ce-0c7e-4cc7-a570-b3047b9f49b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c9b515ce-0c7e-4cc7-a570-b3047b9f49b1",
        "outputId": "c8695142-8606-4b22-c40e-eb3eff9a5567"
      },
      "outputs": [],
      "source": [
        "current_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "current_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "0a697891-a638-4800-9438-ee589380aced",
      "metadata": {
        "id": "0a697891-a638-4800-9438-ee589380aced"
      },
      "outputs": [],
      "source": [
        "cnt = 0\n",
        "patience = 10\n",
        "# A function to encapsulate the training Loop\n",
        "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    best_test_loss = np.inf\n",
        "    best_test_epoch = 0\n",
        "\n",
        "    for it in range(epochs):\n",
        "        model.train()\n",
        "        t0 = datetime.now()\n",
        "        train_loss = []\n",
        "\n",
        "        with tqdm(train_loader, desc='Epoch {}'.format(it+1)) as loop:\n",
        "            for idx, (inputs, targets) in enumerate(loop):\n",
        "                # move data to GPU\n",
        "                inputs = inputs.detach().numpy()\n",
        "                mean_price_value = np.mean(inputs[:, 0, [0, 2]], axis=1).reshape(-1, 1, 1)\n",
        "                inputs[:, :, 0::2] = (inputs[:, :, 0::2] - mean_price_value) / mean_price_value\n",
        "                std_dev = np.std(inputs[:, :, 1::2], axis=(1, 2)).reshape(-1, 1, 1)\n",
        "                inputs[:, :, 1::2] = inputs[:, :, 1::2] / std_dev\n",
        "\n",
        "                inputs, targets = torch.from_numpy(inputs).to(device, dtype=torch.float), targets.to(device, dtype=torch.float)\n",
        "                targets = torch.clamp(targets, min=-10.0, max=10.0)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                # print(outputs)\n",
        "                # print(targets)\n",
        "                loss = criterion(outputs, targets)\n",
        "                # Backward and optimize\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss.append(loss.item())\n",
        "\n",
        "                loop.set_postfix(loss=np.mean(train_loss))\n",
        "\n",
        "            # Get train Loss and test Loss\n",
        "            train_loss = np.mean(train_loss) # a Little misleading\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = []\n",
        "\n",
        "        with tqdm(test_loader, desc='Epoch {}'.format(it+1)) as loop:\n",
        "            for idx, (inputs, targets) in enumerate(loop):\n",
        "                inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.float)\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                loss = criterion(outputs, targets)\n",
        "                test_loss.append(loss.item())\n",
        "\n",
        "        test_loss = np.mean(test_loss)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        if test_loss < best_test_loss:\n",
        "            torch.save(model, './models/{}.pth'.format(current_time))\n",
        "            best_test_loss = test_loss\n",
        "            best_test_epoch = it\n",
        "            print('model saved')\n",
        "            cnt = 0\n",
        "\n",
        "        cnt += 1\n",
        "        if cnt > patience:\n",
        "            break\n",
        "\n",
        "        dt = datetime.now() - t0\n",
        "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
        "            Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
        "\n",
        "    return train_losses, test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d67ad7-838f-4020-9765-acd6eefc8b80",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6d67ad7-838f-4020-9765-acd6eefc8b80",
        "outputId": "4f683d22-fa7e-4ed0-e08a-08b0de5ed379"
      },
      "outputs": [],
      "source": [
        "train_losses, val_losses = batch_gd(model, criterion, optimizer, train_data, val_data, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9598008e-fbb6-45fc-93f3-5ec326a6466f",
      "metadata": {
        "id": "9598008e-fbb6-45fc-93f3-5ec326a6466f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(val_losses, label='validation loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12636244-0407-496b-9404-05f6345b5a89",
      "metadata": {
        "id": "12636244-0407-496b-9404-05f6345b5a89"
      },
      "outputs": [],
      "source": [
        "model = torch.load('./models/{}.pth'.format(current_time)).to(device, dtype=torch.float)\n",
        "target_list = []\n",
        "output_list = []\n",
        "\n",
        "model.eval()\n",
        "for idx, (inputs, targets) in enumerate(test_data):\n",
        "    # Move to GPU\n",
        "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.float)\n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "\n",
        "    target_list.append(targets)\n",
        "    output_list.append(outputs)\n",
        "\n",
        "np.corrcoef(torch.cat(target_list, dim=0).reshape(-1).detach().to('cpu'), torch.cat(output_list, dim=0).reshape(-1).detach().to('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b07bc97b-9f27-499c-b673-bb24c000586b",
      "metadata": {
        "id": "b07bc97b-9f27-499c-b673-bb24c000586b"
      },
      "outputs": [],
      "source": [
        "plt.scatter(torch.cat(target_list, dim=0).detach().to('cpu'), torch.cat(output_list, dim=0).reshape(-1).detach().to('cpu'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kronos",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
